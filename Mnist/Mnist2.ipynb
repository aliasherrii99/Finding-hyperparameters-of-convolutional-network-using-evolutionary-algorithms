{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTV4oRw9RaqC",
        "outputId": "f162e9e5-2d41-43b1-af34-9da16271a451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 / 12\n",
            "populations :  [[4, 9, 8, 59, 6, 13, 6, 33, 7], [4, 48, 8, 25, 6, 13, 5, 33, 7], [3, 9, 8, 59, 6, 40, 6], [3, 9, 8, 25, 3, 28, 5], [2, 48, 8, 19, 6], [3, 9, 8, 59, 6, 40, 6], [3, 9, 8, 59, 6, 13, 5], [4, 9, 8, 59, 6, 40, 5, 33, 7], [2, 48, 8, 25, 6], [4, 48, 8, 19, 6, 13, 6, 33, 7], [3, 48, 8, 59, 6, 40, 6], [2, 9, 8, 19, 6]]\n",
            "Accuracy :  [0.9901999831199646, 0.9901999831199646, 0.9889000058174133, 0.9894000291824341, 0.9901000261306763, 0.9886000156402588, 0.9890000224113464, 0.9878000020980835, 0.9901000261306763, 0.9891999959945679, 0.9833999872207642, 0.9900000095367432]\n",
            "mean :  0.9889083405335745\n",
            "best :  0.9901999831199646\n",
            "11 / 12\n",
            "populations :  [[4, 9, 8, 59, 6, 13, 6, 33, 7], [4, 48, 8, 25, 6, 13, 5, 33, 7], [2, 48, 8, 19, 6], [3, 9, 8, 59, 6, 13, 5], [2, 48, 8, 25, 6], [4, 48, 8, 19, 6, 13, 6, 33, 7], [3, 48, 8, 59, 6, 40, 6], [2, 9, 8, 19, 6], [4, 48, 8, 25, 6, 13, 5, 33, 7], [2, 48, 8, 19, 6], [2, 42, 8, 19, 6], [2, 48, 8, 19, 6]]\n",
            "Accuracy :  [0.9901999831199646, 0.9901999831199646, 0.9901000261306763, 0.9890000224113464, 0.9901000261306763, 0.9891999959945679, 0.9833999872207642, 0.9900000095367432, 0.9905999898910522, 0.9904999732971191, 0.9902999997138977, 0.9896000027656555]\n",
            "mean :  0.9894333332777023\n",
            "best :  0.9905999898910522\n",
            "12 / 12\n",
            "populations :  [[4, 9, 8, 59, 6, 13, 6, 33, 7], [4, 48, 8, 25, 6, 13, 5, 33, 7], [3, 48, 8, 59, 6, 40, 6], [4, 48, 8, 25, 6, 13, 5, 33, 7], [2, 48, 8, 19, 6], [2, 42, 8, 19, 6], [2, 48, 8, 25, 6], [4, 48, 8, 25, 6, 13, 5, 33, 7], [2, 48, 8, 25, 6], [4, 42, 8, 19, 6, 13, 5, 33, 7], [3, 42, 8, 59, 6, 13, 5], [4, 9, 9, 19, 6, 13, 5, 33, 7]]\n",
            "Accuracy :  [0.9901999831199646, 0.9901999831199646, 0.9833999872207642, 0.9905999898910522, 0.9904999732971191, 0.9902999997138977, 0.989799976348877, 0.9905999898910522, 0.9890999794006348, 0.9901000261306763, 0.9905999898910522, 0.9887999892234802]\n",
            "mean :  0.9895166556040446\n",
            "best :  0.9905999898910522\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "from keras import datasets, models, layers, optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "import random\n",
        "\n",
        "seed_value = 42\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
        "\n",
        "train_images = x_train.astype('float32') / 255\n",
        "test_images = x_test.astype('float32') / 255\n",
        "train_labels = to_categorical(y_train)\n",
        "test_labels = to_categorical(y_test)\n",
        "val_images = train_images[:10000]\n",
        "partial_images = train_images[10000:]\n",
        "val_labels = train_labels[:10000]\n",
        "partial_labels = train_labels[10000:]\n",
        "\n",
        "number_of_epochs = 30\n",
        "\n",
        "def create_and_train_model(params):\n",
        "    num_layers = params[0]\n",
        "    num_filters_params = params[1:num_layers + 1]\n",
        "    kernel_sizes_params = params[num_layers + 1:2 * num_layers + 1]\n",
        "\n",
        "    dropout_rate_cnn = 0.1\n",
        "    dropout_rate_mlp = 0.5\n",
        "    optimizer = optimizers.Adam()\n",
        "    activation_function = 'relu'\n",
        "\n",
        "    model = models.Sequential()\n",
        "    input_shape = (28, 28, 1)\n",
        "    num_classes = 10\n",
        "    num_epochs = number_of_epochs\n",
        "\n",
        "    model.add(layers.Conv2D(num_filters_params[0], (kernel_sizes_params[0], kernel_sizes_params[0]), padding='same', input_shape=input_shape, activation=activation_function))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    for i in range(1, num_layers):\n",
        "        kernel_size = kernel_sizes_params[i]\n",
        "        if kernel_size > model.output_shape[1]:\n",
        "            kernel_size = model.output_shape[1]\n",
        "\n",
        "        model.add(layers.Conv2D(num_filters_params[i], (kernel_size, kernel_size), padding='same', activation=activation_function))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "        if i % 2 == 1 and model.output_shape[1] > 2 and model.output_shape[2] > 2:\n",
        "            model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "    if model.output_shape[1] <= 0 or model.output_shape[2] <= 0:\n",
        "        raise ValueError(f\"Output dimensions are invalid: {model.output_shape}\")\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dropout(dropout_rate_cnn))\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(dropout_rate_mlp))\n",
        "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "    es = EarlyStopping(monitor=\"val_accuracy\", patience=3)\n",
        "    history = model.fit(partial_images, partial_labels, validation_data=(val_images, val_labels), epochs=num_epochs, callbacks=[es], verbose=0)\n",
        "\n",
        "    return params, history.history['val_accuracy'][-1]\n",
        "\n",
        "\n",
        "def generate_binary_list(length):\n",
        "    return [random.randint(0, 1) for _ in range(length)]\n",
        "\n",
        "def one_point_crossover(parent1, parent2):\n",
        "    pivot = random.randint(1, min(len(parent1), len(parent2)) - 1)\n",
        "    offspring1 = parent1[:pivot] + parent2[pivot:]\n",
        "    offspring2 = parent2[:pivot] + parent1[pivot:]\n",
        "    offspring1[0] = len(offspring1[1:]) // 2\n",
        "    offspring2[0] = len(offspring2[1:]) // 2\n",
        "    return offspring1, offspring2\n",
        "\n",
        "def crossover(parent1, parent2, current_generation, total_generations):\n",
        "    prob_binary_crossover = 1 - current_generation / total_generations\n",
        "    prob_one_point_crossover = 1 - prob_binary_crossover\n",
        "\n",
        "    if random.random() < prob_binary_crossover:\n",
        "        n = len(parent1)\n",
        "        m = len(parent2)\n",
        "        binary_list = generate_binary_list(max(n, m) - 1)\n",
        "\n",
        "        offspring1 = [parent1[0]]\n",
        "        offspring2 = [parent2[0]]\n",
        "\n",
        "        for i in range(1, min(n, m)):\n",
        "            if binary_list[i-1] == 0:\n",
        "                offspring1.append(parent1[i])\n",
        "                offspring2.append(parent2[i])\n",
        "            else:\n",
        "                offspring1.append(parent2[i])\n",
        "                offspring2.append(parent1[i])\n",
        "\n",
        "        if n > m:\n",
        "            offspring1.extend(parent1[m:])\n",
        "        elif m > n:\n",
        "            offspring2.extend(parent2[n:])\n",
        "\n",
        "    else:\n",
        "        offspring1, offspring2 = one_point_crossover(parent1, parent2)\n",
        "\n",
        "    return offspring1, offspring2\n",
        "\n",
        "def mutate_individual(individual, mutation_rate=0.3):\n",
        "    if random.random() < mutation_rate:\n",
        "        mutation_type = random.choice(['allele', 'layers'])\n",
        "        if mutation_type == 'allele':\n",
        "            idx = random.randint(1, len(individual) - 1)\n",
        "            if idx % 2 == 0:\n",
        "                individual[idx] = random.randint(2, 9)\n",
        "            else:\n",
        "                individual[idx] = random.randint(4, 64)\n",
        "        else:\n",
        "            new_n = random.randint(2, 6)\n",
        "            old_n = individual[0]\n",
        "            individual[0] = new_n\n",
        "            if new_n < old_n:\n",
        "                individual = individual[:-(2 * (old_n - new_n))]\n",
        "            elif new_n > old_n:\n",
        "                additional_genes = []\n",
        "                for _ in range(2 * (new_n - old_n)):\n",
        "                    if len(additional_genes) % 2 == 0:\n",
        "                        additional_genes.append(random.randint(4, 128))\n",
        "                    else:\n",
        "                        additional_genes.append(random.randint(2, 9))\n",
        "                individual.extend(additional_genes)\n",
        "    return individual\n",
        "\n",
        "def mutate_all_pop(pop, score):\n",
        "    new_pop = []\n",
        "    new_score = []\n",
        "\n",
        "    for i in range(len(pop)):\n",
        "        original_individual = pop[i].copy()\n",
        "        mutated_individual = mutate_individual(pop[i])\n",
        "\n",
        "        if original_individual != mutated_individual:\n",
        "            new_pop.append(mutated_individual)\n",
        "            _, new_fitness = create_and_train_model(mutated_individual)\n",
        "            new_score.append(new_fitness)\n",
        "\n",
        "    pop.extend(new_pop)\n",
        "    score.extend(new_score)\n",
        "\n",
        "def tournament_selection(population, scores, k=2):\n",
        "    selected = random.sample(list(zip(population, scores)), k)\n",
        "    selected.sort(key=lambda x: x[1], reverse=True)\n",
        "    return selected[0][0]\n",
        "\n",
        "def create_children(population, scores, number_of_children, current_generation, total_generations):\n",
        "    number_of_children = number_of_children // 2\n",
        "\n",
        "    for _ in range(number_of_children):\n",
        "        parent1 = tournament_selection(population, scores)\n",
        "        parent2 = tournament_selection(population, scores)\n",
        "\n",
        "        child1, child2 = crossover(parent1, parent2, current_generation, total_generations)\n",
        "\n",
        "        child1 = mutate_individual(child1)\n",
        "        child2 = mutate_individual(child2)\n",
        "\n",
        "        try:\n",
        "            a, b = create_and_train_model(child1)\n",
        "            population.append(child1)\n",
        "            scores.append(b)\n",
        "        except Exception as e:\n",
        "            print(f\"Error training child1: {e}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            c, d = create_and_train_model(child2)\n",
        "            population.append(child2)\n",
        "            scores.append(d)\n",
        "        except Exception as e:\n",
        "            print(f\"Error training child2: {e}\")\n",
        "            continue\n",
        "\n",
        "def rank_based_selection(population, scores, num_to_keep):\n",
        "    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
        "\n",
        "    total_rank = sum(range(1, len(ranked_indices) + 1))\n",
        "    probabilities = [(len(ranked_indices) - rank) / total_rank for rank in range(len(ranked_indices))]\n",
        "\n",
        "    selected_indices = set()\n",
        "    while len(selected_indices) < num_to_keep:\n",
        "        selected_index = random.choices(ranked_indices, weights=probabilities, k=1)[0]\n",
        "        selected_indices.add(selected_index)\n",
        "\n",
        "    selected_indices = list(selected_indices)\n",
        "    population[:] = [population[i] for i in selected_indices]\n",
        "    scores[:] = [scores[i] for i in selected_indices]\n",
        "\n",
        "def fitness_based_selection(population, scores, num_to_keep):\n",
        "    total_fitness = sum(scores)\n",
        "    probabilities = [score / total_fitness for score in scores]\n",
        "\n",
        "    selected_indices = set()\n",
        "    while len(selected_indices) < num_to_keep:\n",
        "        selected_index = random.choices(range(len(population)), weights=probabilities, k=1)[0]\n",
        "        selected_indices.add(selected_index)\n",
        "\n",
        "    selected_indices = list(selected_indices)\n",
        "    population[:] = [population[i] for i in selected_indices]\n",
        "    scores[:] = [scores[i] for i in selected_indices]\n",
        "\n",
        "def survivor_selection(population, scores, num_survivors, generation, total_generations):\n",
        "    probability_fitness_based = 1 - generation / total_generations\n",
        "    probability_rank_based = 1 - probability_fitness_based\n",
        "\n",
        "    if random.random() < probability_fitness_based:\n",
        "        fitness_based_selection(population, scores, num_survivors)\n",
        "    else:\n",
        "        rank_based_selection(population, scores, num_survivors)\n",
        "\n",
        "def generate_random_hyperparameters():\n",
        "    first_gene = random.randint(2, 6)\n",
        "    chromosome_length = 1 + 2 * first_gene\n",
        "    chromosome = [first_gene]\n",
        "    for i in range(1, chromosome_length):\n",
        "        if i % 2 == 0:\n",
        "            chromosome.append(random.randint(2, 9))\n",
        "        else:\n",
        "            chromosome.append(random.randint(4, 64))\n",
        "    return chromosome\n",
        "\n",
        "population_size = 12\n",
        "generations = 12\n",
        "number_of_children = 6\n",
        "\n",
        "population = [[4, 9, 8, 59, 6, 13, 6, 33, 7], [4, 9, 8, 59, 6, 40, 6, 33, 7], [4, 9, 8, 59, 6, 13, 6, 33, 7], [5, 9, 8, 57, 6, 60, 6, 33, 7, 6, 5], [4, 48, 8, 25, 6, 13, 5, 33, 7], [3, 9, 8, 59, 6, 40, 6], [3, 9, 8, 25, 3, 28, 5], [2, 48, 8, 19, 6], [4, 9, 8, 4, 6, 40, 6, 33, 7], [3, 9, 8, 59, 6, 40, 6], [3, 9, 8, 59, 6, 13, 5], [4, 9, 8, 25, 3, 28, 6, 33, 7]]\n",
        "scores = []\n",
        "\n",
        "for individual in population:\n",
        "    try:\n",
        "        _, accuracy = create_and_train_model(individual)\n",
        "        scores.append(accuracy)\n",
        "    except Exception as e:\n",
        "        print(f\"Error training individual: {e}\")\n",
        "        scores.append(0)\n",
        "\n",
        "for i in range(9 , generations) :\n",
        "  create_children(population, scores, number_of_children, i , generations)\n",
        "  survivor_selection(population, scores, population_size , i , generations)\n",
        "  print(i + 1  , '/' , generations)\n",
        "  print('populations : ' , population )\n",
        "  print('Accuracy : ' , scores)\n",
        "  print('mean : ' , np.mean(scores))\n",
        "  print('best : ' , np.max(scores))\n"
      ]
    }
  ]
}